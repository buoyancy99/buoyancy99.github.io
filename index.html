<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="keywords"
      content="Boyuan Chen, MIT, UC Berkeley, Personal, Portfolio, Research, AI, Robotics"
    />
    <meta name="description" content="Boyuan's Homepage" />
    <meta name="author" content="Boyuan Chen" />
    <meta
      name="google-site-verification"
      content="pFuPbz82A-vNKOeTAHEyc5do7cSGRbJ2MKQkQofSNUg"
    />

    <title>Boyuan Chen's Homepage</title>

    <!-- favicon -->
    <link href="images/favicon.ico" rel="icon" type="image/png" />

    <!--Font Awesome css-->
    <link rel="stylesheet" href="css/font-awesome.min.css" />

    <!--Bootstrap css-->
    <link rel="stylesheet" href="css/bootstrap.css" />

    <!--Owl Carousel css-->
    <link rel="stylesheet" href="css/owl.carousel.min.css" />
    <link rel="stylesheet" href="css/owl.theme.default.min.css" />

    <!--Magnific Popup css-->
    <link rel="stylesheet" href="css/magnific-popup.css" />

    <!-- Google Fonts -->
    <link
      href="https://fonts.googleapis.com/css?family=Raleway:200,300,400,500,600,700,800,900%7cOpen+Sans:400,600,700,800"
      rel="stylesheet"
    />

    <!--Site Main Style css-->
    <link rel="stylesheet" href="css/style.css" />
  </head>

  <body>
    <!--Preloader-->
    <div class="preloader">
      <div class="loader"></div>
    </div>
    <!--Preloader-->

    <!--Navbar Start-->
    <nav class="navbar navbar-expand-lg navbar-dark">
      <div class="container">
        <!-- LOGO -->
        <a class="navbar-brand logo" href="index.html">
          Boyuan
          <!-- <img src="images/Boyuan_Stamp.png" style="height: 80px;"> -->
        </a>

        <button
          class="navbar-toggler collapsed"
          type="button"
          data-toggle="collapse"
          data-target="#navbarCollapse"
          aria-controls="navbarCollapse"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="navbar-collapse collapse" id="navbarCollapse">
          <ul class="navbar-nav ml-auto">
            <!--Nav Links-->
            <li class="nav-item">
              <a href="#" class="nav-link active" data-scroll-nav="0">Home</a>
            </li>
            <li class="nav-item">
              <a href="#" class="nav-link" data-scroll-nav="1">About</a>
            </li>
            <li class="nav-item">
              <a href="files/Boyuan_Chen_CV.pdf" class="nav-link">Resume</a>
            </li>
            <li class="nav-item">
              <a href="#" class="nav-link" data-scroll-nav="2">Research</a>
            </li>
            <li class="nav-item">
              <a href="#" class="nav-link" data-scroll-nav="3">Projects</a>
            </li>
            <li class="nav-item">
              <a href="#" class="nav-link" data-scroll-nav="4">Blog</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>
    <!--Navbar End-->

    <!--Home Section Start-->
    <section
      id="home"
      class="banner"
      style="background-image: url('images/background/home-banner-bg.jpg')"
      data-stellar-background-ratio=".7"
      data-scroll-index="0"
    >
      <div class="container">
        <!--Banner Content-->
        <div class="banner-caption">
          <h1>Hi! I'm Boyuan.</h1>
          <p class="cd-headline clip mt-30">
            <span>AI Researcher & PhD student at MIT EECS.</span><br />
            <span class="blc">Specialized in</span>
            <span class="cd-words-wrapper">
              <b class="is-visible">machine learning.</b>
              <b>robotics.</b>
              <b>reinforcement learning.</b>
              <b>computer vision.</b>
            </span>
          </p>
        </div>
        <div class="arrow bounce">
          <a class="fa fa-chevron-down fa-2x" href="#" data-scroll-nav="1"></a>
        </div>
      </div>
    </section>
    <!--Home Section End-->

    <!--About Section Start-->
    <section class="about pt-100 pb-100" data-scroll-index="1">
      <div class="container">
        <div class="row">
          <div class="col-lg-5 col-md-6">
            <!--About Image-->
            <div class="about-img">
              <img src="images/about-img.png" alt="" />
            </div>
          </div>
          <div class="col-lg-7 col-md-6">
            <!--About Content-->
            <div class="about-content">
              <div class="about-heading">
                <h2>About Me</h2>
                <span>AI/ML Researcher & Robotics Enthusiast</span>
              </div>
              <p>
                I'm <b>Boyuan Chen (陈博远)</b>. I am currently a second year
                PhD student at MIT EECS working with Prof. Vincent Sitzmann and
                Prof. Russ Tedrake. I am interested in connecting deep learning
                with mathematical structures to power decision making of
                intelligent agents. I hope to use my knowledge and passion to
                tackle the most important challenges in the world and free
                humanities with breakthrough technologies.
              </p>
              <p>
                Before joining MIT, I obtained my bachelor’s degree in computer
                science and math at UC Berkeley, where I spent a signficant
                amount of time doing research at Berkeley Artificial
                Intelligence Research (BAIR) on deep reinforcement learning and
                unsupervised learning. I also spent a year studying philosophy
                during my undergrad. I am a big fan of chess, robots and boba.
              </p>
              <!--About Social Icons-->
              <!-- <div class="social-icons">
                                <a href="#"><i class="fa fa-facebook"></i></a>
                                <a href="#"><i class="fa fa-twitter"></i></a>
                                <a href="#"><i class="fa fa-dribbble"></i></a>
                                <a href="#"><i class="fa fa-google-plus"></i></a>
                                <a href="#"><i class="fa fa-pinterest"></i></a>
                            </div> -->
              <span class="about-button">
                <a class="main-btn" href="files/Boyuan_Chen_CV.pdf"
                  >Resume / CV</a
                >
              </span>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!--About Section End-->

    <!--Research Section Start-->
    <section class="research bg-gray pt-100 pb-50" data-scroll-index="2">
      <div class="container">
        <div class="row">
          <div class="col">
            <div class="heading text-center">
              <h2>My research</h2>
            </div>
          </div>
        </div>

        <!--Paper 4 -->
        <div class="row">
          <div class="col-md-4">
            <div class="paper-thumbnail">
              <a href="https://sites.google.com/view/eil-website">
                <img src="images/research/eil.png" alt="sym" />
              </a>
            </div>
          </div>
          <div class="col-md-8">
            <div class="paper-info" id="eil">
              <a href="https://sites.google.com/view/eil-website">
                <heading>Extraneousness-Aware Imitation Learning </heading>
              </a>
              <br />
              Ray Chen Zheng, Kaizhe Hu, Zhecheng Yuan, Boyuan Chen, Huazhe Xu
              <br />
              Arxiv Pre-print 2022
              <br />
              <br />
              <a href="https://sites.google.com/view/eil-website">webpage</a>
              | <a href="https://arxiv.org/pdf/2210.01379v1.pdf">paper</a> |
              <a href="javascript:toggleblock('eil_abs')">abstract</a> |
              <a
                shape="rect"
                href="javascript:togglebib('eil')"
                class="togglebib"
                >bibtex</a
              >
              |
              <a
                href="https://drive.google.com/file/d/18JSM34ChoVIZtMsJStrc3Oal6fsS5muj/view"
                >talk video</a
              >
              <pre xml:space="preserve" style="display: none">
@misc{https://doi.org/10.48550/arxiv.2210.01379,
  doi = {10.48550/ARXIV.2210.01379},
  url = {https://arxiv.org/abs/2210.01379},
  author = {Zheng, Ray Chen and Hu, Kaizhe and Yuan, Zhecheng and Chen, Boyuan and Xu, Huazhe},
  keywords = {Robotics (cs.RO), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Extraneousness-Aware Imitation Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
              </pre>
            </div>
            <p style="text-align: justify">
              <i id="eil_abs"
                >Visual imitation learning provides an effective framework to
                learn skills from demonstrations. However, the quality of the
                provided demonstrations usually significantly affects the
                ability of an agent to acquire desired skills. Therefore, the
                standard visual imitation learning assumes near-optimal
                demonstrations, which are expensive or sometimes prohibitive to
                collect. Previous works propose to learn from noisy
                demonstrations; however, the noise is usually assumed to follow
                a context-independent distribution such as a uniform or gaussian
                distribution. In this paper, we consider another crucial yet
                underexplored setting — imitation learning with task-irrelevant
                yet locally consistent segments in the demonstrations (e.g.,
                wiping sweat while cutting potatoes in a cooking tutorial). We
                argue that such noise is common in real world data and term them
                as “extraneous” segments. To tackle this problem, we introduce
                Extraneousness-Aware Imitation Learning (EIL), a self-supervised
                approach that learns visuomotor policies from third-person
                demonstrations with extraneous subsequences. EIL learns
                action-conditioned observation embeddings in a self-supervised
                manner and retrieves task-relevant observations across visual
                demonstrations while excluding the extraneous ones. Experimental
                results show that EIL outperforms strong baselines and achieves
                comparable policies to those trained with perfect demonstration
                on both simulated and real-world robot control tasks.</i
              >
            </p>
          </div>
        </div>

        <!--Paper 3 -->
        <div class="row">
          <div class="col-md-4">
            <div class="paper-thumbnail">
              <a href="https://nlmap-saycan.github.io/">
                <img src="images/research/nlmap.png" alt="sym" />
              </a>
            </div>
          </div>
          <div class="col-md-8">
            <div class="paper-info" id="nlmap">
              <a href="https://nlmap-saycan.github.io/">
                <heading
                  >Open-vocabulary Queryable Scene Representations for Real
                  World Planning
                </heading>
              </a>
              <br />
              Boyuan Chen, Fei Xia, Brian Ichter, Kanishka Rao, Keerthana
              Gopalakrishnan, Michael S. Ryoo, Austin Stone, Daniel Kappler
              <br />
              Arxiv Pre-print 2022
              <br />
              <br />
              <a href="https://nlmap-saycan.github.io/">webpage</a>
              | <a href="https://arxiv.org/abs/2209.09874">paper</a> |
              <a href="javascript:toggleblock('nlmap_abs')">abstract</a> |
              <a
                shape="rect"
                href="javascript:togglebib('nlmap')"
                class="togglebib"
                >bibtex</a
              >
              |
              <a href="https://youtu.be/Q9CvvArq4ZA">talk video</a>
              <pre xml:space="preserve" style="display: none">
@inproceedings{chen2022nlmapsaycan,
    title={Open-vocabulary Queryable Scene Representations for Real World Planning},
    author={Boyuan Chen and Fei Xia and Brian Ichter and Kanishka Rao and Keerthana Gopalakrishnan and Michael S. Ryoo and Austin Stone and Daniel Kappler
    booktitle={arXiv preprint arXiv:2209.09874},
    year={2022}
}
              </pre>
            </div>
            <p style="text-align: justify">
              <i id="nlmap_abs"
                >Large language models (LLMs) have unlocked new capabilities of
                task planning from human instructions. However, prior attempts
                to apply LLMs to real-world robotic tasks are limited by the
                lack of grounding in the surrounding scene. In this paper, we
                develop NLMap, an open-vocabulary and queryable scene
                representation to address this problem. NLMap serves as a
                framework to gather and integrate contextual information into
                LLM planners, allowing them to see and query available objects
                in the scene before generating a context-conditioned plan. NLMap
                first establishes a natural language queryable scene
                representation with Visual Language models (VLMs). An LLM based
                object proposal module parses instructions and proposes involved
                objects to query the scene representation for object
                availability and location. An LLM planner then plans with such
                information about the scene. NLMap allows robots to operate
                without a fixed list of objects nor executable options, enabling
                real robot operation unachievable by previous methods.</i
              >
            </p>
          </div>
        </div>

        <!--Paper 2 -->
        <div class="row">
          <div class="col-md-4">
            <div class="paper-thumbnail">
              <a href="https://buoyancy99.github.io/unsup-3d-keypoints/">
                <img src="images/research/keypoint3D.jpg" alt="sym" />
              </a>
            </div>
          </div>
          <div class="col-md-8">
            <div class="paper-info" id="keypoint3D">
              <a href="https://buoyancy99.github.io/unsup-3d-keypoints/">
                <heading
                  >Unsupervised Learning of Visual 3D Keypoints for
                  Control</heading
                >
              </a>
              <br />
              Boyuan Chen, Pieter Abbeel, Deepak Pathak
              <br />
              International Conference on Machine Learning (ICML) 2021
              <br />
              <br />
              <a href="https://buoyancy99.github.io/unsup-3d-keypoints/"
                >webpage</a
              >
              | <a href="https://arxiv.org/abs/2106.07643">paper</a> |
              <a href="javascript:toggleblock('keypoint3D_abs')">abstract</a> |
              <a
                shape="rect"
                href="javascript:togglebib('keypoint3D')"
                class="togglebib"
                >bibtex</a
              >
              |
              <a href="https://github.com/buoyancy99/unsup-3d-keypoints"
                >code</a
              >
              |
              <a href="https://youtu.be/XnRzzxnlMOM">talk video</a>

              <pre xml:space="preserve" style="display: none">
@article{chen2021keypoint3D,
    author = {Chen, Boyuan and Abbeel, Pieter and Pathak, Deepak},
    title  = {Unsupervised Learning of Visual 3D Keypoints for Control},
    journal= {ICML},
    year   = {2021}
}
              </pre>
            </div>
            <p style="text-align: justify">
              <i id="keypoint3D_abs"
                >Learning sensorimotor control policies from high-dimensional
                images crucially relies on the quality of the underlying visual
                representations. Prior works show that structured latent space
                such as visual keypoints often outperforms unstructured
                representations for robotic control. However, most of these
                representations, whether structured or unstructured are learned
                in a 2D space even though the control tasks are usually
                performed in a 3D environment. In this work, we propose a
                framework to learn such a 3D geometric structure directly from
                images in an end-to-end unsupervised manner. The input images
                are embedded into latent 3D keypoints via a differentiable
                encoder which is trained to optimize both a multi-view
                consistency loss and downstream task objective. These discovered
                3D keypoints tend to meaningfully capture robot joints as well
                as object movements in a consistent manner across both time and
                3D space. The proposed approach outperforms prior state-of-art
                methods across a variety of reinforcement learning
                benchmarks.</i
              >
            </p>
          </div>
        </div>

        <!--Paper 1 -->
        <div class="row">
          <div class="col-md-4">
            <div class="paper-thumbnail">
              <a href="https://sites.google.com/view/sapnew/home">
                <img src="images/research/sap.jpg" alt="sym" />
              </a>
            </div>
          </div>
          <div class="col-md-8">
            <div class="paper-info" id="sap">
              <a href="https://sites.google.com/view/sapnew/home">
                <heading
                  >Zero-shot Policy Learning with Spatial Temporal Reward
                  Decomposition on Contingency-aware Observation</heading
                >
              </a>
              <br />
              Boyuan Chen*, Huazhe Xu*, Yang Gao and Trevor Darrell
              <br />
              International Conference on Robotics and Automation (ICRA) 2021
              <br />
              <br />
              <a href="https://sites.google.com/view/sapnew/home">webpage</a> |
              <a href="https://arxiv.org/abs/1910.08143">paper</a> |
              <a href="javascript:toggleblock('sap_abs')">abstract</a> |
              <a
                shape="rect"
                href="javascript:togglebib('sap')"
                class="togglebib"
                >bibtex</a
              >
              | <a href="https://github.com/buoyancy99/sap">code</a> |

              <pre xml:space="preserve" style="display: none">
@article{DBLP:journals/corr/abs-1910-08143,
    author    = {Huazhe Xu and
                    Boyuan Chen and
                    Yang Gao and
                    Trevor Darrell},
    title     = {Scoring-Aggregating-Planning: Learning task-agnostic priors from interactions
                    and sparse rewards for zero-shot generalization},
    journal   = {CoRR},
    volume    = {abs/1910.08143},
    year      = {2019},
    url       = {http://arxiv.org/abs/1910.08143},
    eprinttype = {arXiv},
    eprint    = {1910.08143},
    timestamp = {Fri, 27 Nov 2020 15:04:16 +0100},
    biburl    = {https://dblp.org/rec/journals/corr/abs-1910-08143.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
    }
                            </pre
              >
            </div>
            <p style="text-align: justify">
              <i id="sap_abs"
                >It is a long-standing challenge to enable an intelligent agent
                to learn in one environment and generalize to an unseen
                environment without further data collection and finetuning. In
                this paper, we consider a zero shot generalization problem setup
                that complies with biological intelligent agents' learning and
                generalization processes. The agent is first presented with
                previous experiences in the training environment, along with
                task description in the form of trajectory-level sparse rewards.
                Later when it is placed in the new testing environment, it is
                asked to perform the task without any interaction with the
                testing environment. We find this setting natural for biological
                creatures and at the same time, challenging for previous
                methods. Behavior cloning, state-of-art RL along with other
                zero-shot learning methods perform poorly on this benchmark.
                Given a set of experiences in the training environment, our
                method learns a neural function that decomposes the sparse
                reward into particular regions in a contingency-aware
                observation as a per step reward. Based on such decomposed
                rewards, we further learn a dynamics model and use Model
                Predictive Control (MPC) to obtain a policy. Since the rewards
                are decomposed to finer-granularity observations, they are
                naturally generalizable to new environments that are composed of
                similar basic elements. We demonstrate our method on a wide
                range of environments, including a classic video game -- Super
                Mario Bros, as well as a robotic continuous control task. Please
                refer to the project page for more visualized results.
              </i>
            </p>
          </div>
        </div>

        <!--Paper 0 -->
        <div class="row">
          <div class="col-md-4">
            <div class="paper-thumbnail">
              <a href="https://sites.google.com/view/staghuntrpg">
                <img src="images/research/rpg.jpg" alt="sym" />
              </a>
            </div>
          </div>
          <div class="col-md-8">
            <div class="paper-info" id="rpg">
              <a href="https://sites.google.com/view/staghuntrpg">
                <heading
                  >Discovering Diverse Multi-agent Strategic Behavior via Reward
                  Randomization</heading
                >
              </a>
              <br />
              Zhenggang Tang, Chao Yu, Boyuan Chen, Huazhe Xu, Xiaolong Wang,
              Fei Fang, Simon Shaolei Du, Yu Wang, Yi Wu
              <br />
              International Conference on Learning Representations (ICLR) 2021
              <br />
              <br />
              <a href="https://sites.google.com/view/staghuntrpg">webpage</a> |
              <a href="https://arxiv.org/abs/2103.04564">paper</a> |
              <a href="javascript:toggleblock('rpg_abs')">abstract</a> |
              <a
                shape="rect"
                href="javascript:togglebib('rpg')"
                class="togglebib"
                >bibtex</a
              >
              | <a href="https://github.com/staghuntrpg/RPG">code</a> |

              <pre xml:space="preserve" style="display: none">
@misc{tang2021discovering,
    title={Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization}, 
    author={Zhenggang Tang and Chao Yu and Boyuan Chen and Huazhe Xu and Xiaolong Wang and Fei Fang and Simon Du and Yu Wang and Yi Wu},
    year={2021},
    eprint={2103.04564},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
                            </pre
              >
            </div>
            <p style="text-align: justify">
              <i id="rpg_abs"
                >We propose a simple, general and effective technique, Reward
                Randomization for discovering diverse strategic policies in
                complex multi-agent games. Combining reward randomization and
                policy gradient, we derive a new algorithm, Reward-Randomized
                Policy Gradient (RPG). RPG is able to discover multiple
                distinctive human-interpretable strategies in challenging
                temporal trust dilemmas, including grid-world games(MonsterHunt
                and Escalation) and a real-world web game Agar.io, where
                multiple equilibria exist but standard multi-agent policy
                gradient algorithms always converge to a fixed one with a
                sub-optimal payoff for every player even using state-of-the-art
                exploration techniques (including RND, DIAYN, MAVEN).
                Furthermore, with the set of diverse strategies from RPG, we can
                (1) achieve higher payoffs by fine-tuning the best policy from
                the set; and (2) obtain an adaptive agent by using this set of
                strategies as its training opponents.
              </i>
            </p>
          </div>
        </div>
      </div>
    </section>
    <!--Research Section End-->

    <!--Portfolio Section Start-->
    <section class="portfolio pt-100 pb-70" data-scroll-index="3">
      <div class="container">
        <div class="row">
          <div class="col">
            <div class="heading text-center">
              <h2>MISC</h2>
            </div>
            <div class="portfolio-filter text-center">
              <ul>
                <!-- <li class="sel-item" data-filter="*">All</li> -->
                <li data-filter=".robot">Robots</li>
                <li data-filter=".food">Cooking</li>
                <li data-filter=".team">Teams</li>
              </ul>
            </div>
          </div>
        </div>
        <div class="row portfolio-items">
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/robot_kit.jpg" alt="" />
              <div class="item-overlay">
                <h6>Robomooc Robotics Kit</h6>
                <p>
                  I designed it with my friend, Kinsky. We sold it as an
                  education kit to schools. You can ride on it!
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/robomaster.jpg" alt="" />
              <div class="item-overlay">
                <h6>Robomaster ICRA challenge</h6>
                <p>
                  DJI robomaster robot for ICRA AI Challenge. During my
                  undergrad, I was the captain of the team, leading the
                  development of autonomous algorithms in the robot shooting
                  challenge.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/rover.jpg" alt="" />
              <div class="item-overlay">
                <h6>Autonomous Bogie Rover</h6>
                <p>
                  My personal robot that can handle a variety of terrains. I did
                  everything from machanical design, electronics to programming.
                  It uses computer vision to autonomously follow me and avoid
                  obstables.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/frc17.jpg" alt="" />
              <div class="item-overlay">
                <h6>FRC 2017 Robot</h6>
                <p>
                  In 2017, I founded my high school's first FRC team. We didn't
                  have the mentorship nor funding we need, but the team did
                  amazing. I did the majority of the design.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/pr2.jpg" alt="" />
              <div class="item-overlay">
                <h6>PR2 in RLL</h6>
                <p>
                  In 2021, I graduated from UC Berkeley, where I spent some
                  amazing time doing research in robotics learning lab.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/drone.jpg" alt="" />
              <div class="item-overlay">
                <h6>Autonomous Drone</h6>
                <p>
                  An autonomous drone which I built and coded. I installed a
                  camera a mini railgun on it to track and aim at the target I
                  select.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/ftc17.jpg" alt="" />
              <div class="item-overlay">
                <h6>FTC 2017 Robot</h6>
                <p>
                  Our FTC competition robot in 2017, when I became the captain
                  of the team. It's my team's first robot designed with CAD. The
                  robot won the east China regional.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/ftc16.jpg" alt="" />
              <div class="item-overlay">
                <h6>My first ftc robot</h6>
                <p>
                  In 2016, I participanted in robotics competition for the first
                  time. This is a super cool robot which marks the beginning of
                  my robotics journey.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item robot">
            <div class="item-content">
              <img src="images/portfolio/frc18.jpg" alt="" />
              <div class="item-overlay">
                <h6>FRC 2018 Robot</h6>
                <p>
                  After my graduation from high school, I continued mentoring
                  the team. My successor Xinpei designed the robot under my
                  mentorship.
                </p>
              </div>
            </div>
          </div>

          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item team">
            <div class="item-content">
              <img src="images/portfolio/rm_team.jpg" alt="" />
              <div class="item-overlay">
                <h6>Robomaster Team</h6>
                <p>
                  In 2019, I was the captain of Berkeley's team in ICRA
                  Robomaster AI Challenge. I co-founded the team and lead 20
                  student developing autonomous robots.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item team">
            <div class="item-content">
              <img src="images/portfolio/chess.jpg" alt="" />
              <div class="item-overlay">
                <h6>MIT Chess Club</h6>
                <p>
                  I became one of the execs at MIT Chess Club in 2022. It was a
                  great time to organize events and hangout with the team!
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item team">
            <div class="item-content">
              <img src="images/portfolio/frc_team.jpg" alt="" />
              <div class="item-overlay">
                <h6>FRC Team</h6>
                <p>
                  In 2017, I founded my high school's first FRC team. I worked
                  as both captain and mentor. We won the Rookie All Star Award
                  at CRC 2017.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/newyear22.jpg" alt="" />
              <div class="item-overlay">
                <h6>Chinese New Year 2022</h6>
                <p>
                  To celebrate Chinese New Year 2022, I made a big dinner with
                  my friend Maohao Shen at MIT. MITCSSA awarded me the title
                  Master Chef MIT for my Peking duck in their cooking
                  competition.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/chicken_noodle.jpg" alt="" />
              <div class="item-overlay">
                <h6>Home Style Noodle with Braised Chicken<br />黄焖鸡面</h6>
                <p>I cooked 黄焖鸡 during COVID-19 quarantine!</p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/typical_meal.jpg" alt="" />
              <div class="item-overlay">
                <h6>掌中宝</h6>
                <p>
                  I stir fried 掌中宝 after I was surprised to find it on Weee.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/chicken_soup.jpg" alt="" />
              <div class="item-overlay">
                <h6>Chicken Soup with Mushroom<br />(松茸鸡汤)</h6>
                <p>
                  Traditional Chinese chicken soup with dried matsutake
                  mushroom.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/lamb.jpg" alt="" />
              <div class="item-overlay">
                <h6>Lamb Croutons</h6>
                <p>
                  During the COVID-19 pandemic, I tried to make Lamb Croutons
                  following Gordon Ramsay's tutorial.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/birthday21.jpg" alt="" />
              <div class="item-overlay">
                <h6>Birthday Noodle (长寿面)</h6>
                <p>
                  I made my roommate and long time friend Haoyuan a bowl of
                  traditional birthday noodle in 2021, when he turned 23.
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/brisket.jpg" alt="" />
              <div class="item-overlay">
                <h6>Potato Braised Beef Brisket</h6>
                <p>I cooked beef brisket (土豆炖排骨) in COVID-19 lockdown.</p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/pasta.jpg" alt="" />
              <div class="item-overlay">
                <h6>Pasta</h6>
                <p>
                  I made pasta from scratch (from tomato) during COVID-19
                  quarantine!
                </p>
              </div>
            </div>
          </div>
          <!--Portfolio Item-->
          <div class="col-lg-4 col-md-6 item food">
            <div class="item-content">
              <img src="images/portfolio/huiguorou.jpg" alt="" />
              <div class="item-overlay">
                <h6>Tea Mushroom with Pork Belly<br />(干锅茶树菇)</h6>
                <p>I cooked 干锅茶树菇 during covid-19. It tastes amazing!</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!--Portfolio Section End-->

    <!--Blog Section Start-->
    <section class="blogs pt-100 pb-100 bg-gray" data-scroll-index="4">
      <div class="container">
        <div class="row">
          <div class="col text-center">
            <div class="heading text-center">
              <h2>Blog</h2>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="owl-carousel owl-theme">
            <!--Blogs Item-->
            <div class="blog-item">
              <div class="blog-img">
                <a href="blog1.html">
                  <img src="images/blog/blog1/thumbnail.png" alt="" />
                </a>
              </div>
              <div class="blog-content">
                <h3>Best computer science schools ranked by boba</h3>
                <p>
                  Many people underestimate the importance of boba when they
                  choose grad school. For those who don’t know what boba is ...
                </p>
                <div class="blog-meta">
                  <span class="more">
                    <a href="blog1.html">Read More</a>
                  </span>
                  <span class="date"> 20/Jun/2022 </span>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col text-center">
            <div class="blog-button pt-40">
              <a class="main-btn" href="blogs-page.html">View More</a>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!--Blog Section End-->

    <!--Footer Start-->
    <footer class="pt-50 pb-50">
      <div class="container">
        <!-- <div class="row text-center">
                    <div class="col-md-3 col-sm-6">
                        <div class="contact-info">
                            <h5>Boyuan</h5>
                            <p>lorem Ipsum donor sit.</p>
                        </div>
                    </div>
                    <div class="col-md-3 col-sm-6">
                        <div class="contact-info">
                            <h5>Phone No.</h5>
                            <p>(+1) 123 456 7890</p>
                        </div>
                    </div>
                    <div class="col-md-3 col-sm-6">
                        <div class="contact-info">
                            <h5>Email</h5>
                            <p>info@example.com</p>
                        </div>
                    </div>
                    <div class="col-md-3 col-sm-6">
                        <div class="contact-info">
                            <h5>Address</h5>
                            <p>123 lorem ipsum New York, USA.</p>
                        </div>
                    </div>
                </div> -->
        <div class="row text-center">
          <div class="col-md-12">
            <p class="copy pt-30">
              Boyuan Chen &copy; 2022. All Right Reserved.
            </p>
          </div>
        </div>
      </div>
    </footer>
    <!--Footer End-->

    <!--Jquery js-->
    <script src="js/jquery.min.js"></script>
    <!--Bootstrap js-->
    <script src="js/bootstrap.min.js"></script>
    <!--Stellar js-->
    <script src="js/jquery.stellar.js"></script>
    <!--Animated Headline js-->
    <script src="js/animated.headline.js"></script>
    <!--Owl Carousel js-->
    <script src="js/owl.carousel.min.js"></script>
    <!--ScrollIt js-->
    <script src="js/scrollIt.min.js"></script>
    <!--Isotope js-->
    <script src="js/isotope.pkgd.min.js"></script>
    <!--Magnific Popup js-->
    <script src="js/jquery.magnific-popup.min.js"></script>
    <!--Site Main js-->
    <script src="js/main.js"></script>
    <!--Hide unless clicked js-->
    <script src="js/hidebib.js"></script>

    <!--Hide paper abstract by default-->
    <script xml:space="preserve">
      hideblock("eil_abs");
      hideblock("nlmap_abs");
      hideblock("keypoint3D_abs");
      hideblock("rpg_abs");
      hideblock("sap_abs");
    </script>
  </body>
</html>
